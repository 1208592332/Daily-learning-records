**损失函数**：０－１损失函数　绝对损失函数　对数损失函数　平方损失函数

欠拟合和过拟合					

**正则项**：模型的复杂度计量，模型参数向量的范数（Ｌ２范数、Ｌ１范数）

**生成模型**：由数据学习联合分布，求出条件概率分布作为预测的模型

判别模型：由数据直接学习决策方法或条件概率分布作为预测的模型



**评价指标**：精确率、召回率　Ｆ１值（两值的调和均值）

**感知机：**

​		sign(wx+b)　　损失函数：所有误分类点到超平面的距离之和

ｋ近邻算法：

​	ｋ值的选择、距离度量、分类决策－》ｋｄ树

​	距离度量方式：欧氏距离、曼哈顿距离、（Ｌp距离公式）

​	ｋ值一般去一个较小的值，交叉验证选取最优的ｋ值

​	特殊结构存储训练数据，kd树（二叉树）

​		依次选则坐标轴对空间进行划分，选择训练实例点在坐标轴的中位数为切分点



**朴素贝叶斯的朴素体现**：所有特征都是重要且相互独立

​											Ｐ(AB)=P(A)P(B)

​		贝叶斯估计在原有公式上做拉普拉斯平滑　　分子分母添加参数　λ　Ｓλ

决策树：特征选择－》信息增益或信息增益比（熵与条件熵）－》经验熵和经验条件熵

ID3每次选择信息增益最大作特征为作为节点类

Ｃ4.5选择信息增益比作为节点类

决策树的剪枝：进行损失函数和复杂度的组合的平衡　－》动态规划实现剪枝

分类回归树CART：回归树－》使用平方误差最小化准则

​								分类树－》使用基尼指数最小化准则

　

**逻辑斯谛回归模型：**

​			通过对数几率转化将线性函数转换为概率表示

**支持向量机：**

​			支持向量、最大间隔、软间隔、核函数转换

**提升方法：**

​			Adaboost->训练弱分类器进行组合强分类器（根据分类误差率改变训练数据权重，重新训练计算，重复）

​					提升树（CART算法）

**ＥＭ算法：**??????

**隐马尔科夫模型：**初始状态概率向量、状态转移概率矩阵、观测概率矩阵、状态序列、观测序列

两个假设：齐次马尔可夫性假设（隐藏的马儿可夫链在任意时刻的状态只依赖于前一个时刻的状态，与其他时刻的状态与观测无关）

​					观测独立性假设：假设任意时刻的观测只依赖与该时刻的马儿可夫链的状态

　概率计算、学习算法、预测算法

聚类的核心：相似度或者距离－》闵可夫斯基距离（p=2欧氏距离，ｐ=1曼哈顿距离，ｐ＝无穷切比雪夫距离）

​						相关系数、夹角余弦

ｋ均值聚类：ｋ类别数的选择－》多试进行选择，初始中心点－》可以先层次聚类得到ｋ个类停止，然后从每个类中选一个与中心聚类最近的点

矩阵奇异值分解：特征值与特征向量　　　－》Ａｔ×Ａ　特征值的平方根组成奇异值＝ｒ阶对角矩阵ｍ×ｎ阶奇异值降序排列　　　　特征向量与０特征值组成ｎ阶正交矩阵Ｖ　　Ｕ的求解：Ａ正奇异值及特征向量　　uj =１／Q AV     At的零空间的一组标准正交基　Ｕ＝[u1,u2]



主成分分析：在ｘ的所有线性变换中ｙ＝ａＴｘ＝ａ１＋ａ２ｘ２...

​				ａｔ１ｘ＝所有求和ａｉ１ｘｉ

​				条件下ａｔ１ａ１＝１　　　　　　　　　　　　求方差最大的

























